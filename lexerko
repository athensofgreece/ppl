#include "lex.h"
#include <stdlib.h>
#include <stdio.h>
#include <string.h>
#include <ctype.h>

unsigned int line = 1;

int tokens_index = 0;
int lexeme_index = 0;
int char_class;

#define COMMENT_CLASS 0
#define LETTER 1
#define DIGIT 2
#define OTHER 3

const char* token_type(TokenType type){
    switch(type){
        case VAR_IDENT: return "VAR_IDENT";
        case FUNC_IDENT: return "FUNC_IDENT";
        case ADDITION: return "ADDITION";
        case SUBTRACTION: return "SUBTRACTION";
        case MULTIPLICATION: return "MULTIPLICATION";
        case DIVISION: return "DIVISION";
        case INT_DIVISION: return "INT_DIVISION";
        case ASSIGNMENT_OP: return "ASSIGNMENT_OP";
        case GREATER_THAN: return "GREATER_THAN";
        case LESS_THAN: return "LESS_THAN";
        case IS_EQUAL_TO: return "IS_EQUAL_TO";
        case GREATER_EQUAL: return "GREATER_EQUAL";
        case LESS_EQUAL: return "LESS_EQUAL";
        case NOT_EQUAL: return "NOT_EQUAL";
        case LOG_AND: return "AND";
        case LOG_OR: return "OR";
        case LOG_NOT: return "NOT";
        case INCRE: return "INCREMENT";
        case DECRE: return "DECREMENT";
        case SEMICOLON: return "SEMICOLON";
        case COMMA: return "COMMA";
        case LEFT_PAREN: return "LEFT_PAREN";
        case RIGHT_PAREN: return "RIGHT_PAREN";
        case LEFT_BRACKET: return "LEFT_BRACKET";
        case RIGHT_BRACKET: return "RIGHT_BRACKET";
        case LEFT_BRACE: return "LEFT_BRACE";
        case RIGHT_BRACE: return "RIGHT_BRACE";
        case DBL_QUOTE: return "DBL_QUOTE";
        case SNGL_QUOTE: return "SNGL_QUOTE";
        case COLON: return "COLON";
        case BEEGIN: return "BEEGIN_TOKEN";
        case BEEGONE: return "BEEGONE_TOKEN";
        case BOOL: return "BOOL_TOKEN";
        case BUZZ: return "BUZZ_TOKEN";
        case BUZZOUT: return "BUZZOUT_TOKEN";
        case CASE: return "CASE_TOKEN";
        case CHAR: return "CHAR_TOKEN";
        case CHAIN: return "CHAIN_TOKEN";
        case DEFAULT: return "DEFAULT_TOKEN";
        case DO: return "DO_TOKEN";
        case ELSEIF: return "ELSEIF_TOKEN";
        case ELSE: return "ELSE_TOKEN";
        case FALSE: return "FALSE_TOKEN";
        case FLOAT: return "FLOAT_TOKEN";
        case FOR: return "FOR_TOKEN";
        case GATHER: return "GATHER_TOKEN";
        case HIVE: return "HIVE_TOKEN";
        case HOVER: return "HOVER_TOKEN";
        case IF: return "IF_TOKEN";
        case INT: return "INT_TOKEN";
        case QUEENBEE: return "QUEENBEE_TOKEN";
        case RETURN: return "RETURN_TOKEN";
        case STING: return "STING_TOKEN";
        case SWITCH: return "SWITCH_TOKEN";
        case TRUE: return "TRUE_TOKEN";
        case WHILE: return "WHILE_TOKEN";
        case RETURN_VALUE: return "NOISEWORD";
        case INTEGER: return "INTEGER";
        case FLOAT_LIT: return "FLOAT";
        case CHAR_CONST: return "CHARACTER_CONSTANT";
        default: return "INVALID";
    }
}

void print_token(const Token *token){
    printf("TOKEN: %-20s | TYPE: %-30s | LINE: %zu\n", 
           token->value, token_type(token->type), token->line_num);
}

void write_symbol_table(const Token *token, FILE *symbol_table){
    fprintf(symbol_table, "TOKEN: %-20s | TYPE: %-30s | LINE: %zu\n",
            token->value, token_type(token->type), token->line_num);
}

void free_token(Token *token){
    if (token->value) free(token->value);
    free(token);
}

Token *create_token(TokenType type, const char *value, size_t line_num) {
    Token *token = (Token *)malloc(sizeof(Token));
    if (token) {
        token->type = type;
        token->value = strdup(value);
        if (!token->value) {
            free(token);
            return NULL;
        }
        token->line_num = line_num;
    }
    return token;
}

Token *isIntFloat(const char *source, int *index){
    char buffer[100] = {0};
    int buff_index = 0;
    int decimal = 0;
    int flagged = 0;

    while (isdigit(source[*index]) || (source[*index] == '.') || (isalpha(source[*index]) || ispunct(source[*index]))) {
        if (source[*index] == '.') {
            decimal++;
        } else if (isalpha(source[*index]) || strchr("@#", source[*index])){ 
            flagged++;
        } else if (ispunct(source[*index]) && !(strchr("@#", source[*index]))){ 
            break;
        }

        buffer[buff_index++] = source[(*index)++];
    }

    if (decimal > 1 || flagged){
        fprintf(stderr, "Error: Invalid token '%s' at line %zu\n", buffer, line);
        return create_token(INVALID, buffer, line);
    }

    TokenType type = decimal ? FLOAT_LIT : INTEGER;
    return create_token(type, buffer, line);
}

Token *isString(const char *source, int *index){
    char buffer[300] = {0};
    int buff_index = 0;
    int format = 0;
    int format_specifier = 0;

    (*index)++;

    while (source[*index] != '\"' && source[*index] != '\0'){
        if (format != 0){
            if (strchr("dcfs", source[*index])){
                format_specifier++;
            }

            buffer[buff_index++] = source[(*index)++];
            format = 0;
            continue;
        } else if (source[*index] == '\n'){
            line++;
        } else if (source[*index] == '%'){
            buffer[buff_index++] = source[(*index)++];
            format++;
            continue;
        }
        buffer[buff_index++] = source[(*index)++];
    }

    if (source[*index] == '\"'){
        (*index)++;
    } else {
        fprintf(stderr, "Error: Unterminated string at line %zu\n", line);
    }

    return create_token(format_specifier > 0 ? STR_WITH_FORMAT : STR_CONST, buffer, line);
}

Token *isChar(const char *source, int *index){
    (*index)++;
    char ch = source[*index];

    if (ch == '\0' || ch == '\''){
        fprintf(stderr, "Error: Invalid or empty character at line %zu\n", line);
        return NULL;
    }
    (*index)++;

    if (source[*index] != '\''){
        char buffer[50];
        int buff_index = 0;
        (*index)--;

        fprintf(stderr, "Error: Too many characters in character constant at line %zu\n", line);

        while (source[*index] != '\'' && source[*index] != '\0'){
            buffer[buff_index] = source[*index];
            (*index)++;
            buff_index++;
        }

        if (source[*index] == '\''){
            (*index)++;
        }
        return create_token(INVALID, buffer, line);
    }

    (*index)++;
    char buffer[2] = {ch, '\0'};
    return create_token(CHAR_CONST, buffer, line);
}

Token *isComment(const char *source, int *index) {
    char buffer[256] = {0}; 
    int buffer_index = 0;
    size_t start_line = line;  

    if (source[*index] == '<' && source[*index + 1] == '|') {
        *index += 2;  
        while (!(source[*index] == ':' && source[*index + 1] == '>') && source[*index] != '\0') {
            buffer[buffer_index++] = source[(*index)++];
        }

        if (source[*index] == ':' && source[*index + 1] == '>') {
            *index += 2;
        } else {
            printf("Warning: Unterminated single-line comment at line %zu\n", line);
        }

        return create_token(TOKEN_COMMENT, buffer, start_line);
    }

    return NULL;
}

Token *isKeyReservedWord(const char *lexeme) {
    // Implement similar to lexer file, ensuring we return proper tokens.
    // Simplified implementation for illustration:
    if (strcmp(lexeme, "begin") == 0) return create_token(BEEGIN, lexeme, line);
    // Add similar checks for other keywords...

    return create_token(VAR_IDENT, lexeme, line); // Return VAR_IDENT if not a keyword
}

Token *isOperator(FILE *file, int *line_number) {
    char current = fgetc(file);
    char next = fgetc(file);

    switch (current) {
        case '<':
            if (next == '=') {
                return create_token(LESS_EQUAL, "<=", *line_number);
            }
            ungetc(next, file);
            return create_token(LESS_THAN, "<", *line_number);

        case '>':
            if (next == '=') {
                return create_token(GREATER_EQUAL, ">=", *line_number);
            }
            ungetc(next, file);
            return create_token(GREATER_THAN, ">", *line_number);

        case '=':
            if (next == '=') {
                return create_token(IS_EQUAL_TO, "==", *line_number);
            }
            ungetc(next, file);
            return create_token(ASSIGNMENT_OP, "=", *line_number);

        case '!':
            if (next == '=') {
                return create_token(NOT_EQUAL, "!=", *line_number);
            }
            ungetc(next, file);
            return create_token(LOG_NOT, "!", *line_number);

        case '&':
            if (next == '&') {
                return create_token(LOG_AND, "&&", *line_number);
            }
            ungetc(next, file);
            return create_token(TOKEN_UNKNOWN, "&", *line_number);

        case '|':
            if (next == '|') {
                return create_token(LOG_OR, "||", *line_number);
            }
            ungetc(next, file);
            return create_token(TOKEN_UNKNOWN, "|", *line_number);

        case '+':
            if (next == '+') {
                return create_token(INCRE, "++", *line_number);
            }
            ungetc(next, file);
            return create_token(ADDITION, "+", *line_number);

        case '-':
            if (next == '-') {
                return create_token(DECRE, "--", *line_number);
            }
            ungetc(next, file);
            return create_token(SUBTRACTION, "-", *line_number);

        case '*':
            ungetc(next, file);
            return create_token(MULTIPLICATION, "*", *line_number);

        case '/':
            if (next == '/') {
                return create_token(INT_DIVISION, "//", *line_number);
            }
            ungetc(next, file);
            return create_token(DIVISION, "/", *line_number);

        case '%':
            ungetc(next, file);
            return create_token(MOD_ASSIGN, "%", *line_number);

        case '^':
            ungetc(next, file);
            return create_token(EXPO_OP, "^", *line_number);

        default: {
            char unknown[2] = {current, '\0'};
            ungetc(next, file);
            return create_token(TOKEN_UNKNOWN, unknown, *line_number);
        }
    }
}

Token *isDelimiter(char ch, int line_number) {
    switch (ch) {
        case ';':
            return create_token(SEMICOLON, ";", line_number);
        case ',':
            return create_token(COMMA, ",", line_number);
        case '(':
            return create_token(LEFT_PAREN, "(", line_number);
        case ')':
            return create_token(RIGHT_PAREN, ")", line_number);
        case '[':
            return create_token(LEFT_BRACKET, "[", line_number);
        case ']':
            return create_token(RIGHT_BRACKET, "]", line_number);
        case '{':
            return create_token(LEFT_BRACE, "{", line_number);
        case '}':
            return create_token(RIGHT_BRACE, "}", line_number);
        case '\"':
            return create_token(DBL_QUOTE, "\"", line_number);
        case '\'':
            return create_token(SNGL_QUOTE, "'", line_number);
        case ':':
            return create_token(COLON, ":", line_number);
        default: {
            char unknown[2] = {ch, '\0'};
            return create_token(TOKEN_UNKNOWN, unknown, line_number); 
        }
    }
}

Token **tokenize(const char *source, size_t *token_count) {
    size_t capacity = 10;
    Token **tokens = malloc(capacity * sizeof(Token *));
    *token_count = 0;
    int index = 0;
    int length = strlen(source);

    while (index < length) {
        char c = source[index];

        if (isspace(c)) {
            if (c == '\n') line++;
            index++;
            continue;
        }

        Token *token = NULL;

        if (source[index] == '<') {
            token = isComment(source, &index);
        } else if (isdigit(c)) {
            token = isIntFloat(source, &index);
        } else if (isalpha(c) || c == '_') {
            char buffer[64] = {0};
            int buffer_index = 0;
            int is_flagged = 0;

            while (isalnum(source[index]) || ispunct(source[index])) {
                if (source[index] == '_'){
                } else if (strchr("@#.`?", source[index])) {
                    is_flagged++;
                } else if (ispunct(source[index]) && !strchr("@#.`?", source[index])) {
                    break;
                }
                                
                buffer[buffer_index++] = source[index++];
            }

            if (is_flagged){
                fprintf(stderr, "Error: Invalid token '%s' at line %zu\n", buffer, line);
                token = create_token(INVALID, buffer, line);
            } else {
                token = isKeyReservedWord(buffer);
            }
        } else if (strchr("+-*/=$%^<>!&|", c)) { 
            token = isOperator(source, &index);
        } else if (strchr(";{},()[]", c)) {
            token = isDelimiter(c, line);
            index++; 
        } else if (c == '\"') { 
            token = isString(source, &index);
        } else if (source[index] == '\'') { 
            token = isChar(source, &index);
        } else if (ispunct(source[index])) {
            token = isOperator(source, &index);
            fprintf(stderr, "Error: Unrecognized character '%c' at line %zu\n", c, line);
        }

        if (token) {
            if (*token_count == capacity) {
                capacity *= 2;
                tokens = realloc(tokens, capacity * sizeof(Token *));
            }
            tokens[(*token_count)++] = token;
        }
    }

    return tokens;
}

Token **lexer(FILE *file, size_t *token_count) {
    fseek(file, 0, SEEK_END);
    long file_size = ftell(file);
    rewind(file);

    char *buffer = malloc(file_size + 1);
    fread(buffer, 1, file_size, file);
    buffer[file_size] = '\0';

    Token **tokens = tokenize(buffer, token_count);
    free(buffer);

    return tokens;
}
